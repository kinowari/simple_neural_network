{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perfect-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-repair",
   "metadata": {},
   "source": [
    "## Класс функций потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "formal-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    \"\"\"\n",
    "    Класс содержащий классы функций ошибок,\n",
    "    которые содержат в себе методы вычисляющие потерю и производные.\n",
    "    \n",
    "    Каждый метод классов принимает на вход два массива:\n",
    "    y_true: np.array содержащий настоящии значения\n",
    "    y_pred: np.array содержащий предсказанные значения\n",
    "    \n",
    "    Реализованны слудующие функции потерь:\n",
    "    MSE: mean squeared error\n",
    "    MAE: mean absolute error\n",
    "    RMSE: roof mean squear error\n",
    "    MAPE: mean absolute percentage error\n",
    "    Huber: huber function\n",
    "    LogCosh: logarithm of the hyperbolic cosine error\n",
    "    Log: logarithm error\n",
    "    CosineSimilarity: cosine similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    class Mse:\n",
    "        \n",
    "        def loss(self, y_true, y_pred):\n",
    "            return ((y_true - y_pred) ** 2).mean()\n",
    "        \n",
    "        def deriv(self, y_true, y_pred):\n",
    "            return -2 * (y_true - y_pred)\n",
    "        \n",
    "    class Mae:\n",
    "    \n",
    "        def loss(self, y_true, y_pred):\n",
    "            return (np.abs(y_true - y_pred)).mean()\n",
    "\n",
    "        def deriv(self, y_true, y_pred):\n",
    "            return (y_pred - y_true)/np.abs(y_pred - y_true)\n",
    "        \n",
    "    class Rmse(Mse):\n",
    "\n",
    "        def loss(self, y_true, y_pred):\n",
    "            return np.sqrt(((y_true - y_pred) ** 2).mean())\n",
    "\n",
    "        def deriv(self, y_true, y_pred):\n",
    "            return (1/(2 * Mse.loss(self, y_true[i], y_pred[i]))) * Mse.deriv(self, y_true[i], y_pred[i])\n",
    "        \n",
    "    class Mape:\n",
    "    \n",
    "        def loss(self, y_true, y_pred):\n",
    "            return 100 * (np.abs((y_true - y_pred) / (y_true + np.exp(-20))).mean())\n",
    "\n",
    "        def deriv(self, y_true, y_pred):\n",
    "            return (y_pred - y_true)/(np.abs(y_true + np.exp(-20)) * np.abs(y_pred - y_true))\n",
    "        \n",
    "    class Huber(Mse, Mae):\n",
    "    \n",
    "        def loss(self, y_true, y_pred):\n",
    "            losses = []\n",
    "            for i in range(y_true.size):\n",
    "                if (y_true[i] - y_pred[i]) <= 1:\n",
    "                    losses.append(Mse.loss(self, y_true[i], y_pred[i]))\n",
    "                else: losses.append(Mae.loss(self, y_true[i], y_pred[i]))\n",
    "            return np.array(losses).mean()\n",
    "\n",
    "        def deriv(self, y_true, y_pred):\n",
    "            deriv = []\n",
    "            for i in range(y_true.size):\n",
    "                if (y_true[i] - y_pred[i]) <= 1:\n",
    "                    deriv.append(Mse.deriv(self, y_true[i], y_pred[i]))\n",
    "                else: deriv.append(Mae.deriv(self, y_true[i], y_pred[i]))\n",
    "            return np.array(deriv)\n",
    "        \n",
    "    class LogCosh:\n",
    "    \n",
    "        def loss(self, y_true, y_pred):\n",
    "            return np.log((np.exp(y_true - y_pred) + np.exp(y_pred - y_true))/2).sum()\n",
    "\n",
    "        def deriv(self, y_true, y_pred):\n",
    "            return (np.exp(2 * (y_pred)) - np.exp(2 * (y_true))) / (np.exp(2 * (y_pred)) + np.exp(2 * (y_true)))\n",
    "        \n",
    "    class Log:\n",
    "    \n",
    "        def loss(self, y_true, y_pred):\n",
    "            return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)).sum()\n",
    "\n",
    "        def deriv(self, y_true, y_pred):\n",
    "            return -((y_pred - y_true) / (y_pred**2 - y_pred))\n",
    "        \n",
    "    class CosineSimilarity:\n",
    "        \n",
    "        def loss(self, y_true, y_pred):\n",
    "            return (y_true*y_pred/np.maximum(np.sqrt((y_true**2).sum()*(y_pred**2).sum()), np.exp(-20))).mean()\n",
    "        \n",
    "        def deriv(self, y_true, y_pred):\n",
    "            const = np.maximum(np.sqrt((y_true**2).sum()*(y_pred**2).sum()), np.exp(-20))\n",
    "            return y_pred/const-self.loss(y_true, y_pred)/np.maximum((y_true**2).sum(), np.exp(-20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-malawi",
   "metadata": {},
   "source": [
    "## Класс функций активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "touched-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parametrs\n",
    "class Activation:\n",
    "    \"\"\"\n",
    "    Класс содержащий классы функций активации,\n",
    "    которые содержат в себе методы вычисляющие активацию и производные.\n",
    "    \n",
    "    Каждый метод классов принимает на вход число:\n",
    "    x: int\n",
    "        выходное значение нейрона\n",
    "    \n",
    "    Реализованны слудующие функции активации:\n",
    "    Sigmoid,\n",
    "    Relu,\n",
    "    Leakly_relu.\n",
    "    \"\"\"\n",
    "    \n",
    "    class Sigmoid:\n",
    "        def active(self, x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        def deriv(self, x):\n",
    "            x = self.active(x)\n",
    "            return x * (1 - x)\n",
    "        \n",
    "        \n",
    "    class Relu:\n",
    "        def active(self, x):\n",
    "            return np.maximum(0, x)\n",
    "        \n",
    "        def deriv(self, x):\n",
    "            return np.maximum(0, x)\n",
    "        \n",
    "        \n",
    "    class Leakly_relu:\n",
    "        def active(self, x):\n",
    "            return np.maximum(0.1 * x, x)\n",
    "        \n",
    "        def deriv(self, x):\n",
    "            return np.maximum(0.1 * x, x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-grove",
   "metadata": {},
   "source": [
    "## Класс нейрона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "general-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Один нейрон, объявление класса происходит внутри класс Linear,\n",
    "    начальный вес и смещение инициализируются рандомно\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.sum_neuron = 0\n",
    "        \n",
    "    def forward(self, input_vector):\n",
    "        self.sum_neuron = (np.dot(self.weights, input_vector) + self.bias).ravel()\n",
    "        return self.sum_neuron\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-pottery",
   "metadata": {},
   "source": [
    "## Класс нейроного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "republican-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \"\"\"\n",
    "    Один слой нейронной сети\n",
    "    на вход принимаются значения\n",
    "    input_size: int\n",
    "        число передаваемых связей\n",
    "    output_size: int\n",
    "        число нейронов в слое\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.neurons = []  # хронит нейроны\n",
    "        \n",
    "        for layer in range(output_size):\n",
    "            np.random.seed(21) \n",
    "            self.weights = np.random.rand(1, input_size)  # инициализация веса\n",
    "            np.random.seed(21) \n",
    "            self.bias = np.random.randn()  # инициализация смещения\n",
    "            self.neurons.append(Neuron(self.weights, self.bias))\n",
    "# \n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            n = neuron.forward(inputs).ravel()\n",
    "            outputs.append(n)\n",
    "        return np.array(outputs).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-alarm",
   "metadata": {},
   "source": [
    "## Класс с архетектурой сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "turkish-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \"\"\"Создание нейронной сети\"\"\"\n",
    "    def __init__(self):\n",
    "        self.activation_layer = Activation.Sigmoid()\n",
    "        self.linear1 = Linear(2, 2)\n",
    "        self.linear2 = Linear(2, 1)\n",
    "        self.layers = [self.linear2, self.linear1]  # массив слоев для обратного хода\n",
    "        self.out = []\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        l1 = self.linear1.forward(inputs)\n",
    "        activ_l1 = self.activation_layer.active(l1)\n",
    "        l2 = self.linear2.forward(activ_l1)\n",
    "        result = self.activation_layer.active(l2)\n",
    "        self.out = [result, activ_l1]  # массив выходов для обратного хода\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-columbus",
   "metadata": {},
   "source": [
    "## Реализация обратного распростронения ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "invalid-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(y_true, y_pred, net, inputs, loss, lr): \n",
    "    \"\"\"\n",
    "    На вход принимаются значения:\n",
    "    y_true: list\n",
    "        содержит таргет\n",
    "        \n",
    "    y_pred: list\n",
    "        содержит предсказание\n",
    "        \n",
    "    net: obj Network\n",
    "        объект нашей архетектуры нейронной сети\n",
    "        \n",
    "    inputs: list\n",
    "        входные значения\n",
    "        \n",
    "    loss: obj LossFunction\n",
    "        функция потерь\n",
    "        \n",
    "    lr: float\n",
    "        скорость обучения\n",
    "    \"\"\"        \n",
    "    ypred = loss.deriv(y_true, y_pred)  # производная от функции потери\n",
    "    h = []  # FIFO хранящий значения нейронов\n",
    "    # выход каждого слоя плюс входные значения и единица для удобства\n",
    "    ls = net.out\n",
    "    ls.append(inputs)\n",
    "    ls.append(1)\n",
    "    \n",
    "    layers = net.layers  # массив слоев нейронной сети\n",
    "    for layer in layers:\n",
    "        bias_temp = []  # массив хранящий временные свободные коэффициенты нейрона\n",
    "        for neuron in layer.neurons:\n",
    "            deriv = net.activation_layer.deriv(neuron.sum_neuron)[0]  # производная нейрона\n",
    "            neuron.bias = [(ypred * lr * deriv)]\n",
    "            \n",
    "            weights_temp = []\n",
    "            count = 0 \n",
    "            if layer != layers[0]:\n",
    "                hh = h.pop()\n",
    "            else: hh = 1\n",
    "            for weight in neuron.weights[0]:\n",
    "                \n",
    "                h_temp = ls[layers.index(layer)+1][count]  #h1\n",
    "                weight_temp = h_temp * deriv #w5\n",
    "                \n",
    "                h.append(weight_temp * deriv)  #h1_new\n",
    "                weights_temp.append((weight - (ypred* lr * hh * weight_temp)))\n",
    "\n",
    "                count+=1\n",
    "            weights_temp = np.array(weights_temp).reshape(1, 2)\n",
    "            neuron.weights = weights_temp               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "literary-token",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = Network()\n",
    "learn_rate = 0.1\n",
    "epochs = 100\n",
    "accur  = LossFunction.Mae()\n",
    "loss_f = LossFunction.Mse()\n",
    "y_trues = []\n",
    "def train(data, all_y_trues = None):\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            y_preds = []\n",
    "            for x, y_true in zip(data, all_y_trues):   \n",
    "                y_pred = net.forward(x)\n",
    "                back_prop(y_true, y_pred, net, x, loss_f, learn_rate)\n",
    "                y_preds.append(y_pred[0])\n",
    "\n",
    "          # --- Считаем полные потери в конце каждой эпохи\n",
    "            if epoch % 10 == 0:\n",
    "                accurs = accur.loss(np.array(all_y_trues), y_preds)\n",
    "                losses = loss_f.loss(np.array(all_y_trues), y_preds)\n",
    "                print(\"Epoch %d accur: %.3f, loss: %.3f\" % (epoch, accurs, losses))\n",
    "                \n",
    "# функция для тестового ввода данных               \n",
    "def test(data):\n",
    "#     for x in data:\n",
    "    y_pred = net.forward(data)\n",
    "    return y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "measured-highland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accur: 0.530, loss: 0.283\n",
      "Epoch 10 accur: 0.480, loss: 0.231\n",
      "Epoch 20 accur: 0.416, loss: 0.174\n",
      "Epoch 30 accur: 0.363, loss: 0.134\n",
      "Epoch 40 accur: 0.322, loss: 0.107\n",
      "Epoch 50 accur: 0.290, loss: 0.088\n",
      "Epoch 60 accur: 0.264, loss: 0.074\n",
      "Epoch 70 accur: 0.243, loss: 0.064\n",
      "Epoch 80 accur: 0.225, loss: 0.055\n",
      "Epoch 90 accur: 0.211, loss: 0.049\n"
     ]
    }
   ],
   "source": [
    "# Определим набор данных\n",
    "# Данные включают в себя два параметра: рост, вес ребенка\n",
    "# Показатели смещены на 100 см и 20 кг\n",
    "data = np.array([\n",
    "  [-2, -1],  # Алиса\n",
    "  [25, 6],   # Боб\n",
    "  [17, 4],   # Чарли\n",
    "  [-15, -6], # Диана\n",
    "])\n",
    "all_y_trues = np.array([\n",
    "  1, # Алиса\n",
    "  0, # Боб\n",
    "  0, # Чарли\n",
    "  1, # Диана\n",
    "])\n",
    "\n",
    "# Обучаем нашу нейронную сеть!\n",
    "train(data, all_y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "straight-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмили: 0.839\n",
      "Фрэнк: 0.179\n"
     ]
    }
   ],
   "source": [
    "# Делаем пару предсказаний\n",
    "emily = np.array([-7, -3]) # 128 фунтов (52.35 кг), 63 дюйма (160 см)\n",
    "frank = np.array([20, 2])  # 155 pounds (63.4 кг), 68 inches (173 см)\n",
    "print(\"Эмили: %.3f\" % test(emily)) # 0.951 - Ж\n",
    "print(\"Фрэнк: %.3f\" % test(frank)) # 0.039 - М"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conventional-billy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Класс содержащий классы функций ошибок,\n",
      "    которые содержат в себе методы вычисляющие потерю и производные.\n",
      "    \n",
      "    Каждый метод классов принимает на вход два массива:\n",
      "    y_true: np.array содержащий настоящии значения\n",
      "    y_pred: np.array содержащий предсказанные значения\n",
      "    \n",
      "    Реализованны слудующие функции потерь:\n",
      "    MSE: mean squeared error\n",
      "    MAE: mean absolute error\n",
      "    RMSE: roof mean squear error\n",
      "    MAPE: mean absolute percentage error\n",
      "    Huber: huber function\n",
      "    LogCosh: logarithm of the hyperbolic cosine error\n",
      "    Log: logarithm error\n",
      "    CosineSimilarity: cosine similarity\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(LossFunction.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "infrared-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LossFunction in module __main__:\n",
      "\n",
      "class LossFunction(builtins.object)\n",
      " |  Класс содержащий классы функций ошибок,\n",
      " |  которые содержат в себе методы вычисляющие потерю и производные.\n",
      " |  \n",
      " |  Каждый метод классов принимает на вход два массива:\n",
      " |  y_true: np.array содержащий настоящии значения\n",
      " |  y_pred: np.array содержащий предсказанные значения\n",
      " |  \n",
      " |  Реализованны слудующие функции потерь:\n",
      " |  MSE: mean squeared error\n",
      " |  MAE: mean absolute error\n",
      " |  RMSE: roof mean squear error\n",
      " |  MAPE: mean absolute percentage error\n",
      " |  Huber: huber function\n",
      " |  LogCosh: logarithm of the hyperbolic cosine error\n",
      " |  Log: logarithm error\n",
      " |  CosineSimilarity: cosine similarity\n",
      " |  \n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  CosineSimilarity = <class '__main__.LossFunction.CosineSimilarity'>\n",
      " |  \n",
      " |  Huber = <class '__main__.LossFunction.Huber'>\n",
      " |  \n",
      " |  Log = <class '__main__.LossFunction.Log'>\n",
      " |  \n",
      " |  LogCosh = <class '__main__.LossFunction.LogCosh'>\n",
      " |  \n",
      " |  Mae = <class '__main__.LossFunction.Mae'>\n",
      " |  \n",
      " |  Mape = <class '__main__.LossFunction.Mape'>\n",
      " |  \n",
      " |  Mse = <class '__main__.LossFunction.Mse'>\n",
      " |  \n",
      " |  Rmse = <class '__main__.LossFunction.Rmse'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LossFunction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
